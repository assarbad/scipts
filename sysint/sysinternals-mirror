#!/usr/bin/env python
# -*- coding: utf-8 -*-
# vim: set autoindent smartindent softtabstop=4 tabstop=4 shiftwidth=4 noexpandtab:
__author__ = "Oliver Schneider"
__copyright__ = "2013, 2015 Oliver Schneider (assarbad.net), under Public Domain/CC0, or MIT/BSD license where PD is not applicable"
__version__ = "1.0.1"
import hashlib, os, sys, time

# Checking for compatibility with Python version
if (sys.version_info[0] != 2) or (sys.version_info < (2,7)):
    sys.exit("This script requires Python version 2.7 or better from the 2.x branch of Python.")

# We have two modules stored relative to this script path
sys.path.append(os.path.dirname(os.path.realpath(__file__)))
sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), 'verify-sigs'))
# Additional modules
import argparse, mechanize, re, pyasn1, fingerprint
from HTMLParser import HTMLParser
from datetime import datetime
from os import path

debug = 0
sysint_url = "http://live.sysinternals.com"
override_headers = [
	("User-agent", "Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko"),
	("Accept", "text/html, application/xhtml+xml, */*"),
	("Accept-Charset", ""),
	("Accept-Language", "en-US"),
	("Connection", "Keep-Alive"),
	]
mirror_basepath = None

def verify_signature(fname):
	""" Currently only checks whether the hash in the signature matches """
	with open(fname, 'rb') as f:
		fp = fingerprint.Fingerprinter(f)
		is_pecoff = fp.EvalPecoff()
		fp.EvalGeneric()
		results = fp.HashIt()
		if is_pecoff:
			for r in results:
				if r['name'] == 'pecoff':
					res = r
					if 'SignedData' not in res:
						return False # no signature
					else:
						for hashes in ('md5', 'sha1', 'sha256', 'sha512'):
							if res['SignedData'][0][2].find(res[hashes]) != -1:
								return True
		else:
			return True # Not a PE file, means we pretend this was verified successfully
	return False

def touch(fname, times=None):
	with file(fname, 'a'):
		os.utime(fname, times)

def touchdt(fname, dt):
	numsecs = (dt - datetime(1970, 1, 1)).total_seconds()
	return touch(fname, (numsecs, numsecs))

def parse_index(html_page, baseurl, download_file):
	# Get everything inside the <pre> element
	match = re.search("<pre>(.+)</pre>", html_page, re.DOTALL | re.IGNORECASE)
	if not match:
		return 1 # error
	# Replace links by text, split at converted line breaks
	result = re.sub(r'(?si)<a\s+href="([^"]+)">[^<]+</a><br>', "\\1\n", match.group(1))
	# Now replace HTML entities by their text form
	entities = re.findall("&.+?;", result)
	html = HTMLParser()
	for entity in entities:
		result = result.replace(entity, html.unescape(entity))
	urls = {}
	# Now go over them one by one
	for line in result.split("\n"):
		# Tokenize the lines
		match = re.search("(.{38})\s+(\d+|<dir>)\s+([^\s\n]+)", line, re.IGNORECASE)
		if match:
			# Get a nice representation
			(datestr, sizestr, filename) = (match.group(1).strip(), match.group(2).strip(), match.group(3).strip())
			# Be picky about the items we want
			if re.search(r"\.(exe|dll|chm|hlp)$", filename, re.IGNORECASE) and not re.search(r"pdh\.dll$", filename, re.IGNORECASE):
				# Convert date/time string to a format we can handle more easily
				dt = datetime.strptime(datestr, "%A, %B %d, %Y %I:%M %p")
				# Store the result, hashed by URL
				urls[("%s%s" % (baseurl, filename))] = {
						'size' : int(sizestr),
						'fname': filename.lower(),
						'dt'   : dt,
						'line' : line,
					}
	failures = 0
	# Go through the list keyed by URL
	for url,info in urls.iteritems():
		global mirror_basepath
		fname = path.join(mirror_basepath, path.basename(info['fname']))
		try:
			failures += download_file(url, fname, info['dt'], info['size'])
		except KeyboardInterrupt:
			os.unlink(fname)
			failures += 1
			print "Caught signal. Removed partial file %s." % (fname)
			break
	return failures

def get_index(**kwargs):
	if 'debug' in kwargs:
		global debug
		debug = kwargs['debug']
	br = mechanize.Browser()
	br.set_handle_robots(False)
	br.set_handle_equiv(True)
	br.set_handle_redirect(True)
	br.set_handle_referer(True)
	global override_headers
	br.addheaders = override_headers
	if debug > 0:
		br.set_debug_http(True)
		br.set_debug_redirects(True)
		br.set_debug_responses(True)
	global sysint_url
	response = br.open(sysint_url)
	# Create download directory if it doesn't exist
	if not path.exists(mirror_basepath) and not path.isdir(mirror_basepath):
		os.mkdir(mirror_basepath)
	# Callback for downloading an individual file
	def download_file(url, fname, remotedt, fsize):
		global debug
		# Check whether we need to download the file
		if path.exists(fname):
			locdt = datetime.fromtimestamp(path.getmtime(fname))
			if locdt >= remotedt:
				if debug > 1:
					print "%s remote not newer than local (R:%s <= L:%s)" % (path.basename(fname), remotedt, locdt)
				return 0
		# Download the file
		try:
			if br.retrieve(url, fname):
				print "Downloaded: %s" % fname
				rsize = path.getsize(fname)
				if not rsize == fsize:
					print "ERROR: file size %d does not match expected value %d (%s)!" % (rsize, fsize, fname)
					os.unlink(fname)
					return 1
				if not verify_signature(fname):
					print "ERROR: verification of AuthentiCode signature failed (%s)!" % (fname)
					os.unlink(fname)
					return 1
				touchdt(fname, remotedt)
				return 0
		except (mechanize.HTTPError,mechanize.URLError) as e:
			if isinstance(e,mechanize.HTTPError):
				print "HTTP error code %d [%s]" % (e.code, url)
				if path.exists(fname):
					os.unlink(fname)
			else:
				print "ERROR: %s " % str(e.reason.args)
		return 1
	# Now parse the index HTML file
	return parse_index(response.read(), sysint_url, download_file)

def main(**kwargs):
	global mirror_basepath
	mirror_basepath = kwargs.get('directory')
	get_index(**kwargs)

def parse_args():
	from argparse import ArgumentParser
	parser = ArgumentParser(description='Mirror script for live.sysinternals.com')
	parser.add_argument('--version', '-V', action='version', version=__version__,
						help='show the program version and exit')
	parser.add_argument('--debug', '-d', action='count', default=0,
						help='turn on debugging (more extensive logging) and increase detail')
	parser.add_argument('--directory', '-D', '--dir', action='store', default=path.join(path.dirname(path.realpath(__file__)), 'mirror'),
						help='directory into which to mirror the files', metavar='DIR')
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	sys.exit(main(**vars(args)))
